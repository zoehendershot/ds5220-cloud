# Working with Amazon S3

[**S3 CLI Reference**](https://docs.aws.amazon.com/cli/latest/reference/s3/#cli-aws-s3)

Using the AWS command-line tools, practice with the following exercises:

Make a bucket:
```
aws s3 mb s3://<USERID>-data
# for example s3://nem2p-data
```

Copy a single file from the instructor's bucket into your own:
```
aws s3 cp s3://uvasds-data/taxi/yellow_tripdata_2025-11.parquet s3://nem2p-ds5220-data
```

Copy all files matching a pattern from the instructor's bucket into your own:
```
aws s3 cp s3://uvasds-data/taxi/ s3://nem2p-ds5220-data --recursive --exclude "*" --include "*.parquet" 
```

Sync objects from a source to a destination
```
aws s3 sync SOURCE DESTINATION

# Sync objects from a source and remove files on the destination
# that do not exist in the source

aws s3 sync . s3://amzn-s3-demo-bucket --delete
```

## DuckDB

[**Install the DuckDB CLI**](https://duckdb.org/install/?)

### Remote Queries

```sql
-- a simple select from an S3 object using duckdb
-- UPDATE this s3 URI to the bucket you own
D select * from 's3://uvasds-data/taxi/yellow_tripdata_2025-11.parquet';
```

### Reusable Views

```sql
CREATE VIEW my_s3_data AS 
SELECT * FROM 's3://bucket/data/*.parquet';

-- Now query the view
SELECT * FROM my_s3_data WHERE condition;
```

### Glob Patterns
```sql
D SET s3_use_ssl=true;
D CALL load_aws_credentials();

-- select from all objects matching a pattern
-- UPDATE this s3 URI to the bucket you own
select count(*) from 's3://uvasds-data/taxi/*.parquet';
```

Other
```sql
-- Hive-partitioned data
SELECT * FROM 's3://bucket/data/year=*/month=*/*.parquet';
```

